{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425c7fb2",
   "metadata": {},
   "source": [
    "## CCTVストリーム画像から災害検知するエージェント\n",
    "### 🧩 システム構成（MVP）\n",
    "- graph TD\n",
    "- A[CCTV画像ストリーム] --> B[画像キャプチャ & 前処理]\n",
    "- B --> C[UI-TARS-1.5: Image-to-Text]\n",
    "- C --> D[災害キーワード、災害スコア判定モジュール]\n",
    "- D --> E[位置特定（カメラID → 地図）]\n",
    "- E --> F[被害要約生成]\n",
    "- F --> G[自然言語レポート生成]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da0d1c",
   "metadata": {},
   "source": [
    "#### 1. 📸 画像キャプチャ & 前処理\n",
    "- 各CCTVから定期的に画像を取得（例：1分ごと）\n",
    "- 解像度調整、ノイズ除去、タイムスタンプ付与\n",
    "\n",
    "##### 🔧 必要なツール\n",
    "- | ツール | 用途 | \n",
    "- | ffmpeg | ストリームからフレームを抽出 | \n",
    "- | OpenCV | Pythonで画像処理と保存 | \n",
    "##### インストール\n",
    "- pip install yt-dlp opencv-python\n",
    "- ⇒Successfully installed opencv-python-4.12.0.88 yt-dlp-2025.6.30 \n",
    "- ▼Not well：sudo apt install ffmpeg\n",
    "##### sudo無効の仮想環境での対処法\n",
    "- そのメッセージは、お使いの環境（一部の仮想環境）で sudo 権限が無効化されていることを示しています。以下に、状況別の対処法を整理しました：\n",
    "- 🛠️ 対処法：sudo が無効な環境で ffmpeg を使うには？\n",
    "- ✅ 方法①：ffmpeg をバイナリで直接インストール（推奨）\n",
    "- 公式ffmpegビルドサイト または FFmpeg GitHub から静的バイナリをダウンロード、例（Linux x86_64）:\n",
    "- 実行ファイルをパスに追加（例：~/.local/bin）\n",
    "- 動作確認\n",
    "##### ffmpeg.exe Windows用\n",
    "- ffmpeg（拡張子なし）は Linux用の実行バイナリ\n",
    "- Windowsでは .exe 拡張子のある Windowsネイティブビルド が必要\n",
    "✅ 解決策：Windows向けの正しい ffmpeg.exe を入手する\n",
    "以下の手順で、Windows用の ffmpeg.exe を確実に取得できます：\n",
    "🔗 ステップ1：公式Windowsビルドサイトにアクセス\n",
    "👉 https://www.gyan.dev/ffmpeg/builds/\n",
    "📦 ステップ2：次のいずれかをダウンロード\n",
    "- ffmpeg-release-essentials.zip（軽量で必要最小限）、解凍し、exeを確認\n",
    "✅フォルダーを作成\n",
    "- New-Item -ItemType Directory -Path \"C:\\Tools\\ffmpeg\\bin\" -Force\n",
    "✅環境変数 PATH に追加（永続化）\n",
    "- $env:Path += \";C:\\Tools\\ffmpeg\\bin\"\n",
    "✅ 動作確認\n",
    "- ffmpeg -version → バージョン情報が表示されれば成功です！\n",
    "- ffmpeg version 7.1.1-essentials_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33185db",
   "metadata": {},
   "source": [
    "### 🎥 ストリーム画像取得スクリプト（Windows環境向け）\n",
    "CCTVストリームからの画像取得スクリプトの整備に進みましょう。今回は「球磨川YouTubeライブ映像」などを対象に、1分ごとに静止画像を保存できるMVPコードを用意します。\n",
    "\n",
    "✅ 必要なツール\n",
    "| ツール | 用途 | \n",
    "| yt-dlp | YouTubeライブのストリームURLを取得 | \n",
    "| ffmpeg.exe | ストリームから静止画を抽出 | \n",
    "| PowerShell | スケジュール＆保存処理 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2830377",
   "metadata": {},
   "source": [
    "- PowerShellスクリプトをPythonから実行できるように修正しました。\n",
    "新しいCell In[1]は、subprocessを使ってPowerShellスクリプトを呼び出すPythonコードになっています。\n",
    "- このまま実行すれば、PowerShellの処理がPythonから開始されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b557e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['powershell', '-Command', '\\n$youtubeURL = \"https://www.youtube.com/watch?v=ckuAblc8GCw\"\\n$savePath   = \"C:\\\\Users\\\\yasun\\\\PyTorch\\\\CCTVDisasterAgent\\\\KumagawaFrames\"\\n$ffmpegPath = \"C:\\\\Tools\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"  # 必要に応じて変更\\n$interval   = 10  # 60秒\\n$Num_of_Captures = 3  # 画像取得回数\\nNew-Item -ItemType Directory -Path $savePath -Force | Out-Null\\nfor ($i = 0; $i -lt $Num_of_Captures; $i++) {\\n    $timestamp = Get-Date -Format \"yyyyMMdd_HHmmss\"\\n    $imageFile = \"$savePath\\\\frame_$timestamp.jpg\"\\n    $streamURL = yt-dlp -g $youtubeURL\\n    & \"$ffmpegPath\" -y -i \"$streamURL\" -frames:v 1 \"$imageFile\"\\n    Write-Host \"✅ Saved: $imageFile\"\\n    Start-Sleep -Seconds $interval\\n}\\n'], returncode=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "powershell_script = r'''\n",
    "$youtubeURL = \"https://www.youtube.com/watch?v=ckuAblc8GCw\"\n",
    "$savePath   = \"C:\\Users\\yasun\\PyTorch\\CCTVDisasterAgent\\KumagawaFrames\"\n",
    "$ffmpegPath = \"C:\\Tools\\ffmpeg\\bin\\ffmpeg.exe\"  # 必要に応じて変更\n",
    "$interval   = 10  # 60秒\n",
    "$Num_of_Captures = 3  # 画像取得回数\n",
    "New-Item -ItemType Directory -Path $savePath -Force | Out-Null\n",
    "for ($i = 0; $i -lt $Num_of_Captures; $i++) {\n",
    "    $timestamp = Get-Date -Format \"yyyyMMdd_HHmmss\"\n",
    "    $imageFile = \"$savePath\\frame_$timestamp.jpg\"\n",
    "    $streamURL = yt-dlp -g $youtubeURL\n",
    "    & \"$ffmpegPath\" -y -i \"$streamURL\" -frames:v 1 \"$imageFile\"\n",
    "    Write-Host \"✅ Saved: $imageFile\"\n",
    "    Start-Sleep -Seconds $interval\n",
    "}\n",
    "'''\n",
    "subprocess.run(['powershell', '-Command', powershell_script])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68475961",
   "metadata": {},
   "source": [
    "### 2. 🧠 Qwen2.5-LV-3Bによる画像理解(Image-to-Text LLM Prediction)\n",
    "- 各画像に対して以下のプロンプトを付与：\n",
    "- <|system|> あなたは災害監視エージェントです。\n",
    "- <|user|> この画像に洪水の兆候がありますか？水位、道路冠水、土砂崩れなどを説明してください。\n",
    "- <|vision_start|>...画像トークン...<|vision_end|>\n",
    "##### ⇒出力：自然言語による被害説明（例：「道路が冠水しており、車両が立ち往生している」）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9201ea31",
   "metadata": {},
   "source": [
    "### method. INT4量子化を使ってQwen2.5-LV-3BのようなLLMを軽量化・高速化する\n",
    "- 以下の手順で実装できます。計算環境（RTX 4060 Ti 16GB）なら、INT4量子化は非常に有効です。\n",
    "\n",
    "---\n",
    "\n",
    "#### ⚙️ INT4量子化の実装ステップ（AutoGPTQを例に）\n",
    "#### 🧠 INT4量子化のポイント\n",
    "\n",
    "| 項目 | 内容 |\n",
    "|------|------|\n",
    "| 精度 | INT4はFP16より若干精度が落ちるが、実用上問題ないケースが多い |\n",
    "| メモリ使用量 | 約1/4に削減（FP32比） |\n",
    "| 推論速度 | 約1.5～2倍高速化 |\n",
    "| 対応モデル | GPTQ形式で量子化されたモデル（Hugging Faceで「-GPTQ」表記） |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d638a4",
   "metadata": {},
   "source": [
    "##### ① 必要ライブラリのインストール\n",
    "- Pythonセルでpip installを実行する場合は、コマンドの前に!を付ける必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee95e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting auto-gptq\n",
      "  Downloading auto_gptq-0.7.1-cp311-cp311-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from auto-gptq) (1.8.1)\n",
      "Collecting datasets (from auto-gptq)\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece (from auto-gptq)\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from auto-gptq) (2.3.0)\n",
      "Collecting rouge (from auto-gptq)\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting gekko (from auto-gptq)\n",
      "  Downloading gekko-1.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from auto-gptq) (2.6.0+cu126)\n",
      "Requirement already satisfied: safetensors in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from auto-gptq) (0.5.3)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from auto-gptq) (4.53.2)\n",
      "Collecting peft>=0.5.0 (from auto-gptq)\n",
      "  Downloading peft-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from auto-gptq) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.26.0->auto-gptq) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.26.0->auto-gptq) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.26.0->auto-gptq) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.26.0->auto-gptq) (0.33.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0->auto-gptq) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0->auto-gptq) (2025.5.1)\n",
      "Requirement already satisfied: requests in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0->auto-gptq) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0->auto-gptq) (4.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->auto-gptq) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->auto-gptq) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->auto-gptq) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->auto-gptq) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->auto-gptq) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.31.0->auto-gptq) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.31.0->auto-gptq) (0.21.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->auto-gptq) (21.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->auto-gptq)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->auto-gptq) (2.3.1)\n",
      "Collecting xxhash (from datasets->auto-gptq)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->auto-gptq)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub>=0.21.0->accelerate>=0.26.0->auto-gptq)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->auto-gptq)\n",
      "  Downloading aiohttp-3.12.14-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->auto-gptq)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->auto-gptq)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->auto-gptq) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->auto-gptq)\n",
      "  Using cached frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->auto-gptq)\n",
      "  Using cached multidict-6.6.3-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->auto-gptq)\n",
      "  Using cached propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->auto-gptq)\n",
      "  Using cached yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->auto-gptq) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0->auto-gptq) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0->auto-gptq) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0->auto-gptq) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.13.0->auto-gptq) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yasun\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets->auto-gptq) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets->auto-gptq) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets->auto-gptq) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yasun\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->auto-gptq) (1.17.0)\n",
      "Downloading auto_gptq-0.7.1-cp311-cp311-win_amd64.whl (4.6 MB)\n",
      "   ---------------------------------------- 0.0/4.6 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.0/4.6 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.1/4.6 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.1/4.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.6/4.6 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading peft-0.16.0-py3-none-any.whl (472 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading aiohttp-3.12.14-cp311-cp311-win_amd64.whl (452 kB)\n",
      "Using cached multidict-6.6.3-cp311-cp311-win_amd64.whl (45 kB)\n",
      "Using cached yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Downloading gekko-1.3.0-py3-none-any.whl (13.2 MB)\n",
      "   ---------------------------------------- 0.0/13.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.6/13.2 MB 7.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.1/13.2 MB 9.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.1/13.2 MB 9.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.7/13.2 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.3/13.2 MB 6.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.7/13.2 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.3/13.2 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.2/13.2 MB 8.3 MB/s eta 0:00:00\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Using cached sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Installing collected packages: sentencepiece, xxhash, rouge, propcache, multidict, gekko, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, peft, datasets, auto-gptq\n",
      "\n",
      "   -- -------------------------------------  1/17 [xxhash]\n",
      "   ---- -----------------------------------  2/17 [rouge]\n",
      "   --------- ------------------------------  4/17 [multidict]\n",
      "   ----------- ----------------------------  5/17 [gekko]\n",
      "   ----------- ----------------------------  5/17 [gekko]\n",
      "   ----------- ----------------------------  5/17 [gekko]\n",
      "   ----------- ----------------------------  5/17 [gekko]\n",
      "   ----------- ----------------------------  5/17 [gekko]\n",
      "  Attempting uninstall: fsspec\n",
      "   ----------- ----------------------------  5/17 [gekko]\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "   ----------- ----------------------------  5/17 [gekko]\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "   ----------- ----------------------------  5/17 [gekko]\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "   ----------- ----------------------------  5/17 [gekko]\n",
      "   -------------- -------------------------  6/17 [fsspec]\n",
      "   -------------- -------------------------  6/17 [fsspec]\n",
      "   -------------- -------------------------  6/17 [fsspec]\n",
      "   -------------- -------------------------  6/17 [fsspec]\n",
      "   -------------- -------------------------  6/17 [fsspec]\n",
      "   -------------- -------------------------  6/17 [fsspec]\n",
      "   -------------- -------------------------  6/17 [fsspec]\n",
      "   -------------- -------------------------  6/17 [fsspec]\n",
      "   ------------------ ---------------------  8/17 [dill]\n",
      "   ------------------ ---------------------  8/17 [dill]\n",
      "   ------------------ ---------------------  8/17 [dill]\n",
      "   ------------------ ---------------------  8/17 [dill]\n",
      "   ------------------ ---------------------  8/17 [dill]\n",
      "   ------------------ ---------------------  8/17 [dill]\n",
      "   ------------------ ---------------------  8/17 [dill]\n",
      "   ----------------------- ---------------- 10/17 [yarl]\n",
      "   ------------------------- -------------- 11/17 [multiprocess]\n",
      "   ------------------------- -------------- 11/17 [multiprocess]\n",
      "   ------------------------- -------------- 11/17 [multiprocess]\n",
      "   ------------------------- -------------- 11/17 [multiprocess]\n",
      "   ------------------------- -------------- 11/17 [multiprocess]\n",
      "   ------------------------- -------------- 11/17 [multiprocess]\n",
      "   ------------------------------ --------- 13/17 [aiohttp]\n",
      "   ------------------------------ --------- 13/17 [aiohttp]\n",
      "   ------------------------------ --------- 13/17 [aiohttp]\n",
      "   ------------------------------ --------- 13/17 [aiohttp]\n",
      "   ------------------------------ --------- 13/17 [aiohttp]\n",
      "   ------------------------------ --------- 13/17 [aiohttp]\n",
      "   ------------------------------ --------- 13/17 [aiohttp]\n",
      "   ------------------------------ --------- 13/17 [aiohttp]\n",
      "   ------------------------------ --------- 13/17 [aiohttp]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   -------------------------------- ------- 14/17 [peft]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ----------------------------------- ---- 15/17 [datasets]\n",
      "   ------------------------------------- -- 16/17 [auto-gptq]\n",
      "   ------------------------------------- -- 16/17 [auto-gptq]\n",
      "   ------------------------------------- -- 16/17 [auto-gptq]\n",
      "   ------------------------------------- -- 16/17 [auto-gptq]\n",
      "   ------------------------------------- -- 16/17 [auto-gptq]\n",
      "   ------------------------------------- -- 16/17 [auto-gptq]\n",
      "   ------------------------------------- -- 16/17 [auto-gptq]\n",
      "   ------------------------------------- -- 16/17 [auto-gptq]\n",
      "   ---------------------------------------- 17/17 [auto-gptq]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 auto-gptq-0.7.1 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 gekko-1.3.0 multidict-6.6.3 multiprocess-0.70.16 peft-0.16.0 propcache-0.3.2 rouge-1.0.1 sentencepiece-0.2.0 xxhash-3.5.0 yarl-1.20.1\n",
      "Requirement already satisfied: transformers in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.53.2)\n",
      "Requirement already satisfied: accelerate in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.6.0+cu126)\n",
      "Requirement already satisfied: networkx in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: transformers in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.53.2)\n",
      "Requirement already satisfied: accelerate in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.6.0+cu126)\n",
      "Requirement already satisfied: networkx in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "# Qwen2-VLに必要なライブラリをインストール\n",
    "!pip install transformers>=4.37.0\n",
    "!pip install Pillow\n",
    "!pip install torch torchvision\n",
    "!pip install accelerate\n",
    "# Windows環境向けのbitsandbytesインストール\n",
    "!pip install bitsandbytes --no-deps\n",
    "!pip install bitsandbytes\n",
    "!pip install hf_xet  # Hugging Faceからの高速ダウンロード用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffe1a9",
   "metadata": {},
   "source": [
    "##### ② INT4量子化済みモデルの準備（Hugging Faceから取得）\n",
    "##### 修正内容1：\n",
    "- 正しいモデル名: Qwen/Qwen2-VL-2B-Instruct に変更（実際に存在するモデル）\n",
    "- 適切なライブラリ: Qwen2VLForConditionalGeneration と AutoProcessor を使用\n",
    "- 推論コード: Qwen2.5-VLの正しい推論フォーマットに変更\n",
    "\n",
    "##### 修正内容2：\n",
    "- hf_xetパッケージを追加: Hugging Faceからのダウンロード速度が向上します\n",
    "- メモリ最適化設定を追加:\n",
    "- low_cpu_mem_usage=True: CPUメモリ使用量を削減\n",
    "- use_cache=True: キャッシュを有効化\n",
    "- VRAM使用量の表示を追加\n",
    "\n",
    "##### これらの設定により：\n",
    "- ダウンロード速度が向上\n",
    "- メモリ使用量が最適化される\n",
    "- VRAM使用量を監視できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c6f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hf_xet\n",
      "  Using cached hf_xet-1.1.5-cp37-abi3-win_amd64.whl.metadata (883 bytes)\n",
      "Using cached hf_xet-1.1.5-cp37-abi3-win_amd64.whl (2.7 MB)\n",
      "Installing collected packages: hf_xet\n",
      "Successfully installed hf_xet-1.1.5\n"
     ]
    }
   ],
   "source": [
    "# !pip install hf_xet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be181fbb",
   "metadata": {},
   "source": [
    "##### 修正内容3：\n",
    "- モデル名を修正: Qwen/Qwen2-VL-2B-Instruct に変更（より安定で軽量）\n",
    "- 4bit量子化を追加: BitsAndBytesConfigを使ってVRAM使用量を大幅削減\n",
    "- bitsandbytesライブラリを追加: 量子化に必要なライブラリ\n",
    "###### これらの変更により：\n",
    "-VRAM使用量が約1/2に削減（約6GBになった）\n",
    "- モデルの互換性問題が解決\n",
    "- より安定した動作が期待できます\n",
    "- 量子化により若干の精度低下はありますが、災害検知には十分な性能を維持できるはずです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603f8d7",
   "metadata": {},
   "source": [
    "##### 修正内容4：\n",
    "- bitsandbytesの確実なインストール: --no-deps オプションを使って依存関係の問題を回避\n",
    "- フォールバック機能: bitsandbytesが利用できない場合は通常のBF16モードで動作\n",
    "- エラーハンドリング: ImportErrorをキャッチして適切に処理\n",
    "##### これで以下のような動作になります：\n",
    "- bitsandbytesが正常にインストールされている場合 → 4bit量子化で動作（VRAM約6GB）\n",
    "- bitsandbytesが利用できない場合 → 通常のBF16モードで動作（VRAM約8-12GB）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ff4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.46.1-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch<3,>=2.2 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bitsandbytes) (2.6.0+cu126)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yasun\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
      "Downloading bitsandbytes-0.46.1-py3-none-win_amd64.whl (72.2 MB)\n",
      "   ---------------------------------------- 0.0/72.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/72.2 MB 7.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 2.6/72.2 MB 6.9 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 3.7/72.2 MB 6.2 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 6.3/72.2 MB 7.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 8.7/72.2 MB 8.5 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 11.3/72.2 MB 9.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 13.9/72.2 MB 9.6 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 16.5/72.2 MB 9.8 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 19.1/72.2 MB 10.1 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 21.5/72.2 MB 10.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 24.1/72.2 MB 10.4 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 26.7/72.2 MB 10.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 29.1/72.2 MB 10.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 31.7/72.2 MB 10.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 34.3/72.2 MB 10.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 36.7/72.2 MB 10.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 39.3/72.2 MB 10.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 41.9/72.2 MB 10.9 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 44.3/72.2 MB 11.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 46.9/72.2 MB 11.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 48.8/72.2 MB 11.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 51.4/72.2 MB 11.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 53.7/72.2 MB 11.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 56.4/72.2 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 59.0/72.2 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 61.3/72.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 64.0/72.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 66.3/72.2 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 68.9/72.2 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.3/72.2 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  72.1/72.2 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 72.2/72.2 MB 10.9 MB/s eta 0:00:00\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.46.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3504fe36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yasun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 モデル Qwen/Qwen2-VL-2B-Instruct をダウンロード中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 4bit量子化でモデルを読み込みました\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ モデル Qwen/Qwen2-VL-2B-Instruct の読み込み完了\n",
      "💾 VRAM使用量: 1.42 GB\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "\n",
    "# 正しいQwen2-VLモデル名に修正\n",
    "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"  # 2Bモデルに変更（より安定）\n",
    "\n",
    "print(f\"📥 モデル {model_name} をダウンロード中...\")\n",
    "\n",
    "# bitsandbytesが利用可能かチェック\n",
    "try:\n",
    "    from transformers import BitsAndBytesConfig\n",
    "    \n",
    "    # 4bit量子化設定でVRAM使用量を大幅削減\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "    )\n",
    "    \n",
    "    # モデル読み込み（量子化あり）\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        quantization_config=quantization_config\n",
    "    )\n",
    "    print(\"✅ 4bit量子化でモデルを読み込みました\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"⚠️ bitsandbytesが利用できません。通常モードで読み込みます\")\n",
    "    # 量子化なしでのモデル読み込み\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    print(\"✅ 通常モード（BF16）でモデルを読み込みました\")\n",
    "\n",
    "# プロセッサーの読み込み\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "\n",
    "print(f\"✅ モデル {model_name} の読み込み完了\")\n",
    "print(f\"💾 VRAM使用量: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d12661d",
   "metadata": {},
   "source": [
    "##### ③ 推論の実行(Qwen2-VL-2B-Instruct)\n",
    "- コンセプトは、CCTV画像を10分ごとに取得し、LLMにより災害を検知すること。\n",
    "- 推論の動作確認においては、対象画像のファイル名を入力して、推論を実行した。\n",
    "- 災害の特徴を質問するpromptは、英語を用いた。後に、英語のキーワードを抽出するため。\n",
    "##### テスト画像と推論実行時間\n",
    "- ケース１：雨の後で洪水でないCCTV画像、size FHD 1920x1080、推論時間10～11.7秒/枚\n",
    "- ケース２：実際の河川氾濫画像（ドローン画像）、size 1000x525, 1024x683, 1200x630、推論時間28.3～29.5秒/枚\n",
    "##### 推論時間の考察\n",
    "- 実際の河川氾濫画像では、画像サイズがより小さいにも関わらず、災害の特徴量を詳細に検出しており、推論時間に3倍を要した。\n",
    "- 一方、河川が濁流であっても、氾濫していないCCTV画像は、あっさりと推論時間が短かった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e81f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Qwen2-VL 分析結果:\n",
      "The image shows a bridge over a river, with a calm water surface and no visible signs of flooding or road damage. The bridge appears to be in good condition, and there are no visible signs of distress or damage. The surrounding area is lush with greenery, indicating that the area is likely well-maintained and not affected by natural disasters. The weather appears to be overcast, but there are no visible signs of precipitation or storm activity.\n"
     ]
    }
   ],
   "source": [
    "# Qwen2-VL-2B-Instructを使った画像解析の推論\n",
    "from PIL import Image\n",
    "\n",
    "# 画像パスを設定\n",
    "image_path = r\"C:\\Users\\yasun\\PyTorch\\CCTVDisasterAgent\\8_TestAfterRain\\frame_20250716_090940.jpg\"\n",
    "\n",
    "# 画像を読み込み\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# プロンプトを設定\n",
    "prompt = \"Please analyze this image and describe any signs of flooding, road damage, or disaster impact.\"\n",
    "\n",
    "# 会話形式のメッセージ\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image,\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# プロンプトをテキストに変換\n",
    "text_prompt = processor.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# 入力を処理\n",
    "inputs = processor(\n",
    "    text=text_prompt,\n",
    "    images=image,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# GPUに移動\n",
    "inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "# 推論実行\n",
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "# デコード\n",
    "generated_text = processor.batch_decode(\n",
    "    generated_ids[:, inputs[\"input_ids\"].shape[1]:], \n",
    "    skip_special_tokens=True\n",
    ")[0]\n",
    "\n",
    "print(\"🧠 Qwen2-VL 分析結果:\")\n",
    "print(generated_text)\n",
    "\n",
    "# 後続の処理のために変数を保存\n",
    "description_text = generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3899df71",
   "metadata": {},
   "source": [
    "### 3. 🚨 災害キーワード抽出、災害スコア判定モジュール\n",
    "- 出力文から災害関連キーワードを抽出（例：冠水、氾濫、土砂）\n",
    "- スコアリングして「災害あり／なし」を判定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c76fa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📜 被害説明: The image shows a bridge over a river, with a calm water surface and no visible signs of flooding or road damage. The bridge appears to be in good condition, and there are no visible signs of distress or damage. The surrounding area is lush with greenery, indicating that the area is likely well-maintained and not affected by natural disasters. The weather appears to be overcast, but there are no visible signs of precipitation or storm activity.\n",
      "📊 災害スコア: 0.90\n",
      "🔍 該当キーワード: ['flood', 'damage', 'storm']\n"
     ]
    }
   ],
   "source": [
    "def score_flood_claude(description: str) -> float:\n",
    "    keywords = {\n",
    "        \"flood\": 0.4,\n",
    "        \"overflow\": 0.3,\n",
    "        \"impassable\": 0.4,\n",
    "        \"damage\": 0.3,\n",
    "        \"debris\": 0.2,\n",
    "        \"storm\": 0.2,\n",
    "        \"high water\": 0.3,\n",
    "        \"water level\": 0.3,\n",
    "        \"bridge failure\": 0.5,\n",
    "        \"road washed out\": 0.5\n",
    "    }\n",
    "\n",
    "    score = 0.0\n",
    "    lowered = description.lower()\n",
    "\n",
    "    # キーワードごとにスコアを加算\n",
    "    for word, weight in keywords.items():\n",
    "        if word in lowered:\n",
    "            score += weight\n",
    "    return min(score, 3.0)\n",
    "\n",
    "# 該当したキーワード抽出してリスト化\n",
    "def extract_keywords(description: str) -> list:\n",
    "    keywords = {\n",
    "        \"flood\": 0.4,\n",
    "        \"overflow\": 0.3,\n",
    "        \"impassable\": 0.4,\n",
    "        \"damage\": 0.3,\n",
    "        \"debris\": 0.2,\n",
    "        \"storm\": 0.2,\n",
    "        \"high water\": 0.3,\n",
    "        \"water level\": 0.3,\n",
    "        \"bridge failure\": 0.5,\n",
    "        \"road washed out\": 0.5\n",
    "    }\n",
    "\n",
    "    found_keywords = []\n",
    "    lowered = description.lower()\n",
    "\n",
    "    for word in keywords.keys():\n",
    "        if word in lowered:\n",
    "            found_keywords.append(word)\n",
    "\n",
    "    return found_keywords\n",
    "\n",
    "# Qwen2-VLの出力を使って被害説明の抽出とスコア計算、キーワードリストを表示\n",
    "print(\"📜 被害説明:\", description_text)\n",
    "\n",
    "score = score_flood_claude(description_text)\n",
    "print(f\"📊 災害スコア: {score:.2f}\")\n",
    "found_disaster_words = extract_keywords(description_text)\n",
    "print(\"🔍 該当キーワード:\", found_disaster_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ac3d5",
   "metadata": {},
   "source": [
    "#### JSON形式で出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6c86fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON形式でのレスポンスを保存\n",
    "import json\n",
    "\n",
    "# found_disaster_wordsをテキスト化\n",
    "import os\n",
    "found_disaster_words_text = \", \".join(found_disaster_words) if found_disaster_words else \"None\"\n",
    "\n",
    "response_data = {\n",
    "    \"description\": description_text,\n",
    "    \"score\": score,\n",
    "    \"found_disaster_words\": found_disaster_words_text\n",
    "}   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58d660",
   "metadata": {},
   "source": [
    "#### 5. 📝 被害要約生成\n",
    "- 被害内容を要約し、以下のようなレポートを生成：\n",
    "- 【災害報告】\n",
    "- 主な災害事象：キーワード\n",
    "- 災害スコア：1.3\n",
    "- 災害を検知した画像：ファイル名\n",
    "- 検知時刻：2025年7月9日 06:15\n",
    "- 状況：道路が冠水し、車両が通行不能。水位は歩道を越えている。\n",
    "- 詳細な被害説明：画像から推論出力の全文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c9bac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【災害報告】\n",
      "- 主な災害事象：flood, damage, storm\n",
      "- 災害スコア：0.9\n",
      "- 災害を検知した画像：frame_20250716_090940.jpg\n",
      "- 検知時刻：2025年7月9日 06:15\n",
      "- 状況：The image shows a bridge over a river, with a calm water surface and no visible signs of flooding or road damage. The bridge appears to be in good condition, and there are no visible signs of distress or damage. The surrounding area is lush with greenery, indicating that the area is likely well-maintained and not affected by natural disasters. The weather appears to be overcast, but there are no visible signs of precipitation or storm activity.\n",
      "- 詳細な推論と説明：The image shows a bridge over a river, with a calm water surface and no visible signs of flooding or road damage. The bridge appears to be in good condition, and there are no visible signs of distress or damage. The surrounding area is lush with greenery, indicating that the area is likely well-maintained and not affected by natural disasters. The weather appears to be overcast, but there are no visible signs of precipitation or storm activity.\n",
      "📝 レポートを保存しました: disaster_report_frame_20250716_090940.json\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def generate_disaster_report(description, keywords, score, image_filename, detected_time,description_text):\n",
    "    # スコアの正規化\n",
    "    normalized_score = min(score, 1.0)\n",
    "\n",
    "    # フォーマット用の時刻変換（例: \"20250709_0615\" → \"2025年7月9日 06:15\"）\n",
    "    def format_timestamp(ts_str):\n",
    "        try:\n",
    "            dt = datetime.strptime(ts_str, \"%Y%m%d_%H%M\")\n",
    "            return dt.strftime(\"%Y年%m月%d日 %H:%M\")\n",
    "        except:\n",
    "            return detected_time  # 変換できなければそのまま使う\n",
    "\n",
    "    # レポート本文の生成\n",
    "    report = f\"\"\"\n",
    "【災害報告】\n",
    "- 主な災害事象：{keywords}\n",
    "- 災害スコア：{normalized_score:.1f}\n",
    "- 災害を検知した画像：{image_filename}\n",
    "- 検知時刻：{format_timestamp(image_filename.split(\"frame_\")[-1].split(\".jpg\")[0])}\n",
    "- 状況：{description}\n",
    "- 詳細な推論と説明：{description_text}\n",
    "\"\"\".strip()\n",
    "\n",
    "    return report\n",
    "\n",
    "# レポート生成＆表示\n",
    "report_text = generate_disaster_report(\n",
    "    description=response_data[\"description\"],\n",
    "    keywords=response_data[\"found_disaster_words\"],\n",
    "    score=response_data[\"score\"],\n",
    "    image_filename=os.path.basename(image_path),\n",
    "    detected_time=\"2025年7月9日 06:15\",\n",
    "    description_text=description_text\n",
    ")\n",
    "\n",
    "print(report_text)\n",
    "\n",
    "#　report_textをJSON形式で出力\n",
    "import json\n",
    "report_json = {\n",
    "    \"report\": report_text,\n",
    "    \"image_filename\": os.path.basename(image_path),\n",
    "    # \"detected_time\": \"2025年7月9日 06:15\"\n",
    "}\n",
    "#   保存するファイル名に、画像ファイル名を含める\n",
    "report_filename = f\"disaster_report_{os.path.basename(image_path).split('.')[0]}.json\"\n",
    "with open(report_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(report_json, f, ensure_ascii=False, indent=4)\n",
    "print(f\"📝 レポートを保存しました: {report_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db8b9f",
   "metadata": {},
   "source": [
    "#### Note1.**GPUクラッシュがいくつかの要因で複合発生した可能性**\n",
    "\n",
    "---\n",
    "\n",
    "##### 🧠 モデルとGPU構成のマッチング評価\n",
    "\n",
    "| 項目 | 条件 | 影響 |\n",
    "|------|------|------|\n",
    "| モデルサイズ | Qwen2.5-LV-3B（約3Bパラメータ） | 中規模モデル |\n",
    "| 推論形式 | 画像入力あり（1280×720 HD） | メモリ消費増加（特にマルチモーダル） |\n",
    "| GPU | ASUS RTX 4060 Ti 16GB GDDR6 | VRAMは十分。ただしメモリ帯域はミッドレンジ |\n",
    "\n",
    "---\n",
    "\n",
    "##### ⚠️ 推論クラッシュの可能性要因\n",
    "\n",
    "1. **マルチモーダル推論のVRAM消費量**\n",
    "   - Qwen2.5-LVは画像も扱うため、**画像埋め込み・Transformer処理でVRAMを大量に消費**します。\n",
    "   - HD画像1枚でも内部でトークンに分割後、**最大128Kコンテキスト長を許容する構造**のため、メモリ爆発が起こる可能性があります。\n",
    "\n",
    "2. **FlashAttention未使用 / Efficient Layer未導入**\n",
    "   - メモリ節約技術（例：FlashAttention2、PagedAttention、xFormers）を使っていない場合、**VRAMが急激に枯渇**します。\n",
    "\n",
    "3. **16GB VRAMの内訳とOS使用分**\n",
    "   - 実際に使えるのは14～15GB程度。さらに**CUDAカーネルやドライバ、XLAのオーバーヘッド**が入ると残りが圧迫されます。\n",
    "\n",
    "---\n",
    "\n",
    "##### ✅ 対処・改善案\n",
    "\n",
    "| 方法 | 具体策 | 利点 |\n",
    "|------|--------|------|\n",
    "| 量子化 | INT4/Q8モデルに切替（例：AutoGPTQ, bitsandbytes） | メモリ節約、推論高速化 |\n",
    "| コンテキスト制限 | 入力長を256～1024程度に制限 | VRAM消費大幅減 |\n",
    "| 高速Attention | FlashAttention2やPagedAttentionの導入 | メモリ効率化・速度改善 |\n",
    "| バッチサイズ | 単一推論（batch=1）にする | メモリ爆発の回避 |\n",
    "| 推論フレームワーク | vLLMやOpenVINOなど軽量推論ライブラリを使用 | VRAM最適化、クラッシュ防止 |\n",
    "\n",
    "---\n",
    "##### ✅ 実行結果\n",
    "- 実際に、**テスト画像2に対して、Qwen2-VL-2B-Instructを用いて推論した結果、6GBの容量を必要**とした。\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406097a3",
   "metadata": {},
   "source": [
    "#### Note2. **VRAM（Video RAM）とは、GPU専用の高速メモリ**\n",
    "- 画像や映像などのグラフィックスデータを一時的に保存・処理するために使われます。CPUが使うRAMとは異なり、GPUが描画処理を効率よく行うための作業領域です。\n",
    "\n",
    "---\n",
    "\n",
    "##### 🔍 VRAMの役割と特徴\n",
    "\n",
    "- **GPUが扱う画像・映像・テクスチャなどを一時保存**\n",
    "- **高解像度・高フレームレートの描画に不可欠**\n",
    "- **ゲーム、動画編集、AI推論などで使用量が増加**\n",
    "- **GDDR6やGDDR7など、RAMより高速な規格を採用**\n",
    "\n",
    "---\n",
    "\n",
    "##### 🧠 VRAMとRAMの違い\n",
    "\n",
    "| 項目 | VRAM | RAM（メインメモリ） |\n",
    "|------|------|----------------------|\n",
    "| 用途 | GPUの画像・映像処理 | CPUの一般的な処理 |\n",
    "| 接続先 | グラフィックボード | マザーボード |\n",
    "| 処理対象 | テクスチャ、フレームバッファなど | OS、アプリ、データ処理など |\n",
    "| 規格 | GDDR6, GDDR7など | DDR4, DDR5など |\n",
    "\n",
    "---\n",
    "\n",
    "##### ⚠️ VRAM不足で起こる現象\n",
    "\n",
    "- テクスチャが表示されない、画面がカクつく\n",
    "- フレームレート低下（fps drop）\n",
    "- 最悪の場合、アプリやゲームがクラッシュ\n",
    "\n",
    "---\n",
    "\n",
    "VRAMは、GPUの性能を引き出すための「専用作業机」のようなもの。容量が多いほど、複雑で高精細な処理がスムーズになります。  \n",
    "AI推論や最適化処理を行う場合も、モデルサイズやコンテキスト長に応じてVRAMの確保が重要になります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
